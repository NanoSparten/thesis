% Encoding: UTF-8

@article{pan_roughness_2020,
  title    = {Roughness {Analysis} of {Sea} {Surface} {From} {Visible} {Images}
  by {Texture}},
  volume   = {8},
  issn     = {2169-3536},
  doi      = {10.1109/ACCESS.2020.2978638},
  abstract = {This paper presents a roughness
  analysis of sea surface from visible images by feature measurements of texture
  for the first time. The algorithms presented in this paper include six texture
  feature measurements of sea surface use gray level co-occurrence matrix, gray
  level-gradient co-occurrence matrix, Tamura texture feature, autocorrelation
  function, edge frequency and fractional Brownian motion autocorrelation. The
  empirical relationship between wind speeds (or sea surface roughness) and
  image texture roughness are estimated based on the extracted data. Our
  experiments have demonstrated that our texture methods and empirical relation
  between wind speeds and image texture roughness can potentially be used to
  analyze sea surface roughness from visible images.},
  journal  = {IEEE Access},
  author   = {Pan, Hailang and Gao, Peilin and Zhou, Huicheng and Ma, Ruixue and
  Yang, Jingsong and Zhang, Xin},
  year     = {2020},
  keywords = {Rough surfaces,
  Surface roughness, Surface waves, Optical surface waves, Sea surface
  roughness, Sea measurements, Sea surface roughness, gray level co-occurrence
  matrices, gray level-gradient co-occurrence matrices, tamura texture features,
  autocorrelation function, edge frequency, fractional Brownian motion},
  pages    = {46448--46458}
}

@inproceedings{ganga_survey_2021,
  title     = {Survey of {Texture} {Based} {Image} {Processing} and {Analysis}
  with {Differential} {Fractional} {Calculus} {Methods}},
  doi       = {10.1109/ICSCAN53069.2021.9526439},
  abstract  = {In image processing systems,
  image denoising, and image enhancement is an essential problem but it is
  difficult to analyze. These are aim to achieve the enhancing the quality of
  image which helps to achieve the human observer or the computer vision system
  in the preprocessing stage. The efficient technique of developing a
  fractional-based convolution mask based on the image denoising and image
  enhancement approaches which are having the ability to identify the edges in a
  detailed manner very substantially. The credible way of the above approaches
  is to differentiate between the important image features which are kept or
  evenly enhanced. In this paper, a review of various image processing
  application texture image enhancement processes using mathematical formulas
  like fractional derivative calculus with various conventional works. Here
  review the various existing methods in enhancement of image processing
  methods.},
  booktitle = {2021 {International} {Conference} on {System},
  {Computation}, {Automation} and {Networking} ({ICSCAN})},
  author    = {Ganga,
  M. and Janakiraman, N. and Sivaraman, Arun Kumar and Balasundaram, A and
  Vincent, Rajiv and Rajesh, M},
  month     = jul,
  year      = {2021},
  keywords  = {Computer vision, Convolution, Image edge detection, Noise reduction,
  Observers, Calculus, Image enhancement, image processing, denoising,
  enhancement, fractional derivative calculus, convolution mask},
  pages     = {1--6}
}

@inproceedings{chen_characterization_2021,
  title     = {Characterization of tissue texture with {Mueller} matrix
  parameters},
  doi       = {10.1109/ICOIM52180.2021.9524414},
  abstract  = {Polarization is a fundamental property of light and a powerful sensing tool,
  and it has been applied to the detection of biological tissues. Parameters
  from the Mueller matrix polar decomposition (MMPD) method and Mueller matrix
  transformation (MMT) method are potential mathematical descriptions of the
  polarization characteristics of scattering media. However, the robustness of
  the parameters is affected by the complex scattering of polarized light within
  biological tissues. In this work, we conducted comparations and analyses of
  the image textures of these parameters, and the results indicate that not all
  parameters from MMPD and MMT methods can distinguish the textural features of
  different types of scatterers in tendon tissue. Spherical scatterer regions
  exhibit more obvious textural properties than cylindrical scatterers regions.
  And there exist differences between the value distribution of spherical and
  cylindrical scatterers regions, which corresponds to different sections at the
  color bar. This work may provide a reference for the textural characterization
  of biological tissues with the parameters from MMPD and MMT methods.},
  booktitle = {2021 {International} {Conference} of {Optical} {Imaging} and
  {Measurement} ({ICOIM})},
  author    = {Chen, Yongtai and Xin, Benda and Zhao,
  Mingyu and Chu, Jinkui},
  month     = aug,
  year      = {2021},
  keywords  = {Image color analysis, Biological tissues, Scattering, Tools, Optical
  variables measurement, Robustness, Sensors, Mueller matrix imaging, image
  texture, tissue imaging, polarization characterization},
  pages     = {127--130}
}

@inproceedings{lu_paper_2021,
  title     = {Paper {Dating} {Analysis} {Based} on {Paper} {Texture} {Image}
  {Feature}},
  doi       = {10.1109/ICoIAS53694.2021.00010},
  abstract  = {Paper
  dating analysis is an important research direction of document inspection,
  which is widely used in the inspection and identification of cultural relics
  and ancient books. This article focuses on the analysis of paper dating in
  ancient books, and proposes a non-destructive inspection and analysis method
  based on paper fiber texture images. Aiming at the global stacking morphology
  of paper fibers and the local features of specific types of fiber morphology,
  we propose a neural network-based hybrid texture feature extraction and
  representation method: On the one hand, we use convolutional networks to
  obtain global features of fiber texture; at the same time, we designed a
  method of extracting and representing local fiber morphological features based
  on the attention mechanism. By mixing the above two types of features, we
  realize the extraction and representation of paper fiber features.
  Furthermore, we use the GRU(Gate Recurrent Unit) model to establish a paper
  dating time series model and design a new loss function. In order to verify
  the method, this paper selects 36 domestic books published from 1950 to 2000,
  and uses the document checker VSC 6000 to collect paper texture images as a
  dataset, and verifies the effectiveness of the proposed method on this
  dataset. Experiments prove that the method proposed in this paper has achieved
  ideal results in paper dating analysis.},
  booktitle = {2021 4th
  {International} {Conference} on {Intelligent} {Autonomous} {Systems}
  ({ICoIAS})},
  author    = {Lu, Qi and Zhu, Ziqi and Li, Zhihao and Lian, Zhe},
  month     = may,
  year      = {2021},
  keywords  = {Time series analysis,
  Stacking, Neural networks, Layout, Morphology, Production, Optical fiber
  networks, paper dating analysis, neural network, regression model, attention
  mechanism, GRU},
  pages     = {13--17}
}

@inproceedings{xu_integrating_2009,
  title     = {Integrating local feature and global statistics for texture
  analysis},
  doi       = {10.1109/ICIP.2009.5413361},
  abstract  = {A main
  challenge for texture analysis is to construct a compact texture descriptor
  which is not only highly discriminative to intra-class textures, but also
  robust to inter-class variations, geometric and photometric changes. In this
  paper, a new texture descriptor is developed by integrating the local
  affine-invariant texture features and the global viewpoint-invariant
  statistics. Based on the pixel clustering using two state-of-art robust local
  texture descriptors (i.e. SIFT and SPIN), the proposed texture descriptor
  enables impressive invariance to a wide range of environmental changes (e.g.
  view changes, illumination changes, surface distortions) by characterizing the
  spatial distribution of pixel sets using multi-fractal analysis. Experiments
  on some real datasets (publicly available) showed that the proposed texture
  descriptor achieved better performance than some state-of-art techniques in
  texture retrieval and texture classification while the computation cost is
  significantly reduced.},
  booktitle = {2009 16th {IEEE} {International}
  {Conference} on {Image} {Processing} ({ICIP})},
  author    = {Xu, Yong and
  Huang, SiBin and Ji, Hui},
  month     = nov,
  year      = {2009},
  note      = {ISSN: 2381-8549},
  keywords  = {Statistical analysis, Robustness, Lighting,
  Fractals, Histograms, Image texture analysis, Pixel, Shape, Surface texture,
  Information retrieval, Image texture analysis, image classification, image
  recognition, pattern recognition, feature extraction},
  pages     = {1377--1380}
}

@inproceedings{vacha_illumination_2009,
  title     = {Illumination invariant and rotational insensitive textural
  representation},
  doi       = {10.1109/ICIP.2009.5413578},
  abstract  = {We
  propose an illumination invariant and rotation insensitive texture
  representation based on a Markovian textural model. A texture is aligned with
  its dominant orientation and textural features are derived from fast
  analytical estimates of Markovian statistics. We do not require any knowledge
  of illumination direction or spectrum. This makes our method suitable for
  computer analysis of real scenes, where appearance of materials depends on
  their orientation towards the illumination source. Our method is tested on the
  most realistic visual representation of natural materials - the bidirectional
  texture function (BTF), using data from the CUReT database, where it
  outperforms the alternative leading illumination invariant Local Binary
  Patterns (LBP) and texton MR8 methods, respectively.},
  booktitle = {2009 16th
  {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
  author    = {Vácha, Pavel and Haindl, Michal},
  month     = nov,
  year      = {2009},
  note      = {ISSN: 2381-8549},
  keywords  = {Lighting, Histograms, Algorithm design and
  analysis, Layout, Spatial databases, Markov random fields, Rough surfaces,
  Surface roughness, Information theory, Automation, Illumination invariance,
  Markov random fields, texture features},
  pages     = {1333--1336}
}

@inproceedings{zhang_feature_2007,
  title     = {Feature {Reduction} and {Texture} {Classification} in
  {MRI}-{Texture} {Analysis} of {Multiple} {Sclerosis}},
  doi       = {10.1109/ICCME.2007.4381839},
  abstract  = {The aim of this study was to
  investigate the performance of texture analysis in texture classification and
  tissue discrimination between MS lesions, normal appearing white matter (NAWM)
  and normal white matter (NWM) in order to support early diagnosis of MS.
  T2-weighted MR images of sixteen relapsing remitting MS (RRMS) patients and
  sixteen healthy subjects were selected. Based on the lesion size, sixteen
  regions of interests (ROIs) were chosen from MS patient MR images and healthy
  subject MR images for MS lesions, NAWM and NWM respectively. Texture features
  extracted from grey level co-occurrence matrix (GLCM) were selected based on
  greatest feature difference. For statistical analysis, raw data analysis
  (RDA), principal component analysis (PCA) and nonlinear discriminant analysis
  (NDA) were applied to the texture features. The k-nearest neighbor (k-NN) and
  artificial neural network (ANN) methods were used for texture classification.
  Fisher coefficient and classification accuracy were used to evaluate the
  performance of texture analysis. The results demonstrated that (1)
  classification was successful ({\textgreater}90.00\%) between MS lesions and
  NAWM or NWM, less successful (88.89\%) among the three tissue groups and worst
  (66.67\%) between NAWM and NWM; (2) In statistical analysis, NDA outperforms
  RDA and PCA; (3) ANN classified more accurately than k-NN method between NAWM
  and NWM, and among the three texture types. This study demonstrated that MRI
  texture analysis can achieve high classification accuracy in tissue
  discrimination between MS lesions and NAWM or NWM, which is valuable in
  supporting early diagnosis of MS.},
  booktitle = {2007 {IEEE}/{ICME}
  {International} {Conference} on {Complex} {Medical} {Engineering}},
  author    = {Zhang, Jing and Wang, Lei and Tong, Longzheng},
  month     = may,
  year      = {2007},
  keywords  = {Multiple sclerosis, Lesions, Image texture analysis,
  Principal component analysis, Artificial neural networks, Performance
  analysis, Statistical analysis, Image analysis, Feature extraction, Data
  mining, Multiple Sclerosis, MRI, Texture Analysis, Feature Selection, Texture
  Classification},
  pages     = {752--757}
}

@inproceedings{feng_study_2009,
  title     = {Study on {Chinese} handwriting identification based on texture
  analysis},
  doi       = {10.1109/ICWAPR.2009.5207424},
  abstract  = {As a kind
  of behavior-based personal identification techniques, automated Chinese
  handwriting identification becomes a hot topic in pattern recognition and
  machine learning research area. There are lots of key issues worthy
  researching. In this paper, the Chinese handwriting identification technology
  based on texture analysis is discussed. Firstly, a practical Chinese
  handwriting image samples library CHSL2007 is established for the comparison
  of exist algorithms and further research. Then the methods of feature
  extraction based on texture analysis are explored and the pairwise SVM
  classifier is utilized. The experiment results of texture analysis based on
  Gabor filter is compared with DB6 wavelet filter and demonstrate that the
  former is more suitable for handwriting identification on CHSL2007. Finally,
  the sheet recognition rate is defined and can be arrived at above 99.50\% for
  CHSL2007.},
  booktitle = {2009 {International} {Conference} on {Wavelet}
  {Analysis} and {Pattern} {Recognition}},
  author    = {Feng, Jun and Gao, Xu},
  month     = jul,
  year      = {2009},
  note      = {ISSN: 2158-5709},
  keywords  = {Image texture analysis, Gabor filters, Pattern recognition, Machine
  learning, Libraries, Machine learning algorithms, Feature extraction, Support
  vector machines, Support vector machine classification, Wavelet analysis,
  Handwriting identification, Texture feature analysis, SVM classifier, Chinese
  handwriting samples library},
  pages     = {215--219}
}

@inproceedings{vacha_illumination_2009-1,
  title     = {Illumination invariant and rotational insensitive textural
  representation},
  doi       = {10.1109/ICIP.2009.5413578},
  abstract  = {We
  propose an illumination invariant and rotation insensitive texture
  representation based on a Markovian textural model. A texture is aligned with
  its dominant orientation and textural features are derived from fast
  analytical estimates of Markovian statistics. We do not require any knowledge
  of illumination direction or spectrum. This makes our method suitable for
  computer analysis of real scenes, where appearance of materials depends on
  their orientation towards the illumination source. Our method is tested on the
  most realistic visual representation of natural materials - the bidirectional
  texture function (BTF), using data from the CUReT database, where it
  outperforms the alternative leading illumination invariant Local Binary
  Patterns (LBP) and texton MR8 methods, respectively.},
  booktitle = {2009 16th
  {IEEE} {International} {Conference} on {Image} {Processing} ({ICIP})},
  author    = {Vácha, Pavel and Haindl, Michal},
  month     = nov,
  year      = {2009},
  note      = {ISSN: 2381-8549},
  keywords  = {Lighting, Histograms, Algorithm design and
  analysis, Layout, Spatial databases, Markov random fields, Rough surfaces,
  Surface roughness, Information theory, Automation, Illumination invariance,
  Markov random fields, texture features},
  pages     = {1333--1336}
}

@inproceedings{ghofrani_new_2010,
  title     = {A new rotation-invariant and noise-resistant method for texture
  analysis and classification},
  doi       = {10.1109/ICECTECH.2010.5479953},
  abstract  = {One of the basic and important topics in image processing
  especially for textures is image analysis and classification. In reality,
  there are some destructive parameters such as "rotation" and "noise" in
  images. Removing the aforementioned defects has recently become a challenge
  for many researchers, and consequently various methods have been proposed so
  far. Among the recently presented methods those based on the multi-resolution
  transforms have been more popular. This paper presents a new method for
  texture analysis which is combination of Wavelet, Ridgelet and Fourier
  transforms. Our approach not only is capable to remove the rotation and noise
  defects but also in comparison with other approaches its computational cost is
  less. The method is tested on five datasets, one dataset contains noise free
  rotated textures and the others are noisy rotated textures. Each dataset
  includes 2880 textures that produced from 20 main textures. These 20 textures
  belong to Brodatz album. The results show appropriate performance of the
  method for texture classification even though the textures are rotated and
  added with noise.},
  booktitle = {2010 2nd {International} {Conference} on
  {Electronic} {Computer} {Technology}},
  author    = {Ghofrani, Sedigheh and
  Feraidooni, Mohammad Mahdi},
  month     = may,
  year      = {2010},
  keywords  = {Image texture analysis, Wavelet transforms, Fourier transforms, Image
  analysis, Wavelet analysis, Image processing, Pattern analysis, Wavelet
  packets, Computational efficiency, Testing, texture classification,
  multi-resolution analysis, rotation invariant, Ridgelet transform, wavelet
  transform, Radon transform},
  pages     = {218--222}
}

@inproceedings{he_texture_2010,
  title     = {Texture analysis and classification for clinker in rotary kiln},
  volume    = {1},
  doi       = {10.1109/OPEE.2010.5508151},
  abstract  = {This
  paper presents a potential application of texture analysis and classifier for
  a set of sintered clinkers in rotary kiln. This approach, which consists of
  the extraction of clinker from the whole image, GLCM texture features
  computation, and C4.5 classification, provides an efficient way for untouched
  on-line analysis of sintered clinker for the automatic control of industrial
  rotary kiln. 69 clinker images from an alumina rotary kiln were employed, 5
  sets of 14 texture features were computed based on GLCM of different
  distances, texture feature classification were achieved by C4.5 algorithm, all
  graphic illustrations of classification rule are given as a function of
  texture ID. Experimental results demonstrate that it is effective to classify
  these sintered clinkers of different qualities. This paper may provide a basis
  for analyzing other kinds of industrial materials in rotary kiln.},
  booktitle = {2010 {International} {Conference} on {Optics}, {Photonics} and {Energy}
  {Engineering} ({OPEE})},
  author    = {He, Min and Yan, Min and Zhang, Jing and
  Chen, Hua},
  month     = may,
  year      = {2010},
  note      = {ISSN:
  2158-7442},
  keywords  = {Kilns, Image texture analysis, Cement industry, Image
  analysis, Algorithm design and analysis, Automatic control, Computer industry,
  Industrial control, Metals industry, Graphics, texture analysis, clinker,
  rotary kiln, c4.5, GLCM},
  pages     = {211--214}
}

@inproceedings{zujovic_structural_2009,
  title     = {Structural similarity metrics for texture analysis and
  retrieval},
  doi       = {10.1109/ICIP.2009.5413897},
  abstract  = {The
  development of objective texture similarity metrics for image analysis
  applications differs from that of traditional image quality metrics because
  substantial point-by-point deviations are possible for textures that according
  to human judgment are essentially identical. Thus, structural similarity
  metrics (SSIM) attempt to incorporate ¿structural¿ information in image
  comparisons. The recently proposed structural texture similarity metric
  (STSIM) relies entirely on local image statistics. We extend this idea further
  by including a broader set of local image statistics, basing the selection on
  metric performance as compared to subjective evaluations. We utilize both
  intra- and inter-subband correlations, and also incorporate information about
  the color composition of the textures into the similarity metrics. The
  performance of the proposed metrics is compared to PSNR, SSIM, and STSIM on
  the basis of subjective evaluations using a carefully selected set of 50
  texture pairs.},
  booktitle = {2009 16th {IEEE} {International} {Conference} on
  {Image} {Processing} ({ICIP})},
  author    = {Zujovic, Jana and Pappas,
  Thrasyvoulos N. and Neuhoff, David L.},
  month     = nov,
  year      = {2009},
  note      = {ISSN: 2381-8549},
  keywords  = {Image texture analysis, Image
  retrieval, Statistics, Humans, Image coding, Image quality, PSNR, Wavelet
  domain, Image color analysis, Image analysis, Steerable filter decomposition,
  dominant colors, image retrieval, image compression},
  pages     = {2225--2228}
}


@inproceedings{seck_3d_2014,
  title     = {{3D} {Facial} {Skin} {Texture} {Analysis} {Using} {Geometric}
	{Descriptors}},
  doi       = {10.1109/ICPR.2014.203},
  abstract  = {We compare skin
	texture classification using various 2D texture descriptors and their
	extensions to 3D surface orientation data. We perform a multi-resolution
	analysis on both the 2D and 3D data. Rotation-Invariant Local Binary Patterns,
	Multiple Orientations Gabor Filters and Center-Symetric Autocorrelation are
	used to extract 2D texture features from high resolution facial skin albedo
	patches. For extracting texture feature directly from the corresponding normal
	map patches, we propose extensions of these texture measures in both the
	slant/tilt and tangent spaces. We compare the results of classifying facial
	wrinkles and pores using the 2D-based and 3D-based texture features. We use
	the 3DRFE dataset which consists of high resolution 3D facial scans along with
	the corresponding photometric and albedo images. We notice a net improvement
	on classifying both wrinkle and pore using the 3D orientation based features
	over the 2D ones.},
  booktitle = {2014 22nd {International} {Conference} on
	{Pattern} {Recognition}},
  author    = {Seck, Alassane and Dee, Hannah and
	Tiddeman, Bernard},
  month     = aug,
  year      = {2014},
  note      = {ISSN: 1051-4651},
  keywords  = {Skin, Three-dimensional displays, Surface texture, Rough surfaces,
	Surface roughness, Feature extraction, Lighting},
  pages     = {1126--1131}
}

@inproceedings{liu_texture_2014,
  title     = {Texture {Analysis} with {Shape} {Co}-occurrence {Patterns}},
  doi       = {10.1109/ICPR.2014.288},
  abstract  = {This paper presents a flexible
	shape-based texture analysis method by investigating the co-occurrence
	patterns of shapes. More precisely, a texture image is represented by a tree
	of shapes, each of which is associated with several attributes. The modeling
	of texture is thus converted to characterize the tree of shapes. To this aim,
	we first learn a set of co-occurrence patterns of shapes from texture images,
	then establish a bag-of-words model on the learned shape co-occurrence
	patterns (SCOPs), and finally use the resulting SCOPs distributions as
	features for texture analysis. In contrast with existing work, the proposed
	method not only inherits the strong ability to depict geometrical aspects of
	textures and the high robustness to variations of imaging conditions from the
	shape-based texture analysis method, but also provides a more flexible way to
	model shape relationships (high-order statistics) on the tree. To our
	knowledge, this is the first time to use co-occurrence patterns of explicit
	shapes as a tool for texture analysis. Experiments of texture retrieval and
	classification on various databases report state-of-the-art results and
	demonstrate the efficiency of the proposed method.},
  booktitle = {2014 22nd
	{International} {Conference} on {Pattern} {Recognition}},
  author    = {Liu, Gang
	and Xia, Gui-Song and Yang, Wen and Zhang, Liangpei},
  month     = aug,
  year      = {2014},
  note      = {ISSN: 1051-4651},
  keywords  = {Shape, Databases, Analytical
	models, Level set, Transforms, Histograms, Training},
  pages     = {1627--1632}
}

@inproceedings{sidiropoulos_texture_2021,
  title     = {Texture {Analysis} for {Machine} {Learning} {Based} {Marble} {Tiles}
	{Sorting}},
  doi       = {10.1109/CCWC51732.2021.9376086},
  abstract  = {In this paper,
	the classification of ornamental dolomitic marble stone tiles, in regard to
	their aesthetical value, was studied based on the rock's texture. The stone
	tiles examined are of a dolomitic marble variety commercially known as Lais
	Grey. Twenty four (24) texture descriptors and seven (7) machine learning
	models were tested in order to find the best performing combination. The
	experimental study was conducted with an in-house dataset consisting of three
	tile classes containing digital images selected by an expert. A second dataset
	was compiled by applying clustering using the k-means algorithm, towards
	defining the tiles' quality based on texture information. This process
	produced a dataset with two classes. The results revealed that the XCS-LBP
	texture descriptor joined by the XGBoost classifier achieved the best
	performance for screening the tiles into three (with 65.06\% F1-score) or two
	(with 99.43 \% F1-score) quality classes.},
  booktitle = {2021 {IEEE} 11th
	{Annual} {Computing} and {Communication} {Workshop} and {Conference}
	({CCWC})},
  author    = {Sidiropoulos, George K. and Ouzounis, Athanasios G. and
	Papakostas, George A. and Sarafis, Ilias T. and Stamkos, Andreas and Solakis,
	George},
  month     = jan,
  year      = {2021},
  keywords  = {Machine learning algorithms,
	Conferences, Digital images, Clustering algorithms, Machine learning,
	Classification algorithms, Sorting, machine vision, texture descriptors,
	machine learning, marble tiles, dolomite, quality control},
  pages     = {0045--0051}
}

@inproceedings{ghosh_automated_2020,
  title     = {Automated {Detection} and {Localization} of {Counterfeit} {Chip}
	{Defects} by {Texture} {Analysis} in {Infrared} ({IR}) {Domain}},
  doi       = {10.1109/PAINE49178.2020.9337739},
  abstract  = {Today's globalized supply chain
	for electronics design, fabrication, and distribution has resulted in a
	proliferation of counterfeit chips. Recycled and remarked chips are the most
	common counterfeit types in the market, and prior work has shown that physical
	inspection is the best approach to detect them. However, it can be
	time-consuming, expensive, and destructive while relying on the use of subject
	matter experts. This paper proposes a low-cost, automated detection technique
	that examines surface variations within and between chips to identify
	defective chips. Further, it can estimate the location of the defects for
	additional analysis. The proposed method only requires a cheap IR camera-based
	setup to capture images of the chip package surface and is completely
	unsupervised and non-destructive. Experimental results on 25 chips in our lab
	demonstrate 100\% detection accuracy.},
  booktitle = {2020 {IEEE} {Physical}
	{Assurance} and {Inspection} of {Electronics} ({PAINE})},
  author    = {Ghosh,
	Pallabi and Botero, Ulbert J and Ganji, Fatemeh and Woodard, Damon and
	Chakraborty, Rajat Subhra and Forte, Domenic},
  month     = dec,
  year      = {2020},
  keywords  = {Integrated circuits, Location awareness, Supply chains,
	Inspection, Feature extraction, Surface texture, Tuning},
  pages     = {1--6}
}

@inproceedings{abdeldayem_automatically_2018,
  title     = {Automatically {Detecting} {Arrhythmia}-related {Irregular} {Patterns}
	using the {Temporal} and {Spectro}-{Temporal} {Textures} of {ECG} {Signals}},
  doi       = {10.1109/ICPR.2018.8546045},
  abstract  = {Arrhythmia is an abnormal heart
	rhythm that occurs due to the improper operation of the electrical impulses
	that coordinate the heartbeats. It is one of the most well-known heart
	conditions (including coronary artery disease, heart failure etc.) that is
	experienced by millions of people around the world. While there are several
	types of arrhythmias, not all of them are dangerous or harmful. However, there
	are arrhythmias that can often lead to death in minutes (e.g, ventricular
	fibrillation and ventricular tachycardia) even in young people. Thus, the
	detection of arrhythmia is critical for stopping and reversing its progression
	and for increasing longevity and life quality. While a doctor can perform
	different heart-monitoring tests specific to arrhythmias, the
	electrocardiogram (ECG) is one of the most common ones used either
	independently or in combination with other tests (to only detect, e.g.
	echocardiogram, or trigger arrhythmia and, then, detect, e.g. stress test). We
	propose a machine learning approach that augments the traditional arrhythmia
	detection approaches via our automatic arrhythmia classification system. It
	utilizes the texture of the ECG signal in both the temporal and
	spectro-temporal domains to detect and classify four types of heartbeats. The
	original ECG signal is first preprocessed, and then, the R-peaks associated
	with heartbeat estimation are identified. Next, 1D local binary patterns (LBP)
	in the temporal domain are utilized, while 2D LBPs and texture-based features
	extracted by a grayscale co-occurrence matrix (GLCM) are utilized in the
	spectro-temporal domain using the short-time Fourier transform (STFT) and
	Morse wavelets. Finally, different classifiers, as well as different ECG lead
	configurations are examined before we determine our proposed time-frequency
	SVM model, which obtains a maximum accuracy of 99.81\%, sensitivity of
	98.17\%, and specificity of 99.98\% when using a 10 cross-validation on the
	MIT-BIH database. Our approach yields competitive accuracy when compared to
	other methods discussed in the literature.},
  booktitle = {2018 24th
	{International} {Conference} on {Pattern} {Recognition} ({ICPR})},
  author    = {Abdeldayem, Sara S. and Bourlai, Thirimachos},
  month     = aug,
  year      = {2018},
  note      = {ISSN: 1051-4651},
  keywords  = {Electrocardiography, Feature extraction,
	Heart beat, Time-frequency analysis, Medical services, Wavelet transforms},
  pages     = {2301--2307}
}

@article{bianconi_cnn-based_2019,
  title      = {{CNN}-{Based} {Refactoring} of {Hand}-{Designed} {Filters} for
	{Texture} {Analysis}: {A} {Classic} {Revisited}},
  volume     = {7},
  issn       = {2169-3536},
  shorttitle = {{CNN}-{Based} {Refactoring} of {Hand}-{Designed}
	{Filters} for {Texture} {Analysis}},
  doi        = {10.1109/ACCESS.2019.2956863},
  abstract   = {Filtering has been one of the main approaches to texture analysis
	since early on. Traditionally, the process involved designing the filters
	essentially by hand based on some prior knowledge (e.g. perceptual models,
	optimal mathematical properties, etc.) In this work we propose the use of
	convolutional networks for refactoring traditional, hand-designed filters. Our
	method consists of initialising the first convolutional layer of the network
	with some classic banks of filters, training the network on texture images and
	retrieve the modified filters. Experimenting with five classes of filters and
	eight datasets of texture images we show that the refactored filters can be
	conveniently used `off-the-shelf' to achieve better performance than obtained
	with the original filters, but at the same computational cost.},
  journal    = {IEEE Access},
  author     = {Bianconi, Francesco and Cusano, Claudio and
	Napoletano, Paolo and Schettini, Raimondo},
  year       = {2019},
  keywords   = {Feature
	extraction, Training, Machine learning, Kernel, Convolution, Gabor filters,
	Computational efficiency, Texture analysis, convolutional neural networks,
	image filters},
  pages      = {173076--173085}
}

@inproceedings{sghaier_flood_2017,
  title     = {Flood hazard mapping from {SAR} images using texture analysis and
	fuzzy logic},
  doi       = {10.1109/IGARSS.2017.8127349},
  abstract  = {Floods rank
	among the most devastating and deadly disasters likely to occur. Each year,
	thousands of people die as a result of rising river water levels and spring
	snow melts. Minimizing the impact of these events and providing necessary
	information to rescue teams on the ground requires the mobilization of all
	humanitarian stakeholders. This work aims to automate the extraction of
	flooded areas from Synthetic Aperture Radar (SAR) satellite images in order to
	accelerate the generation of damage maps during floods. Our approach is mainly
	based on the following steps: first, homogeneous surfaces contained in pre-
	and post-disaster images are extracted based on the Structural Feature Set
	(SFS) texture descriptor. Then, a morphological opening operator is applied to
	the resulting images in order to filter out small-sized objects and noise.
	Finally, the two gray levels images generated by applying the texture
	descriptor and the morphological operator are fused using fuzzy logic to
	identify flooded regions. SAR images acquired using the RADARSAT-2 satellite
	during the Richelieu River floods are used to evaluate the performance of the
	proposed technique, and the results obtained show the efficiency and
	robustness of the described approach.},
  booktitle = {2017 {IEEE}
	{International} {Geoscience} and {Remote} {Sensing} {Symposium} ({IGARSS})},
  author    = {Sghaier, Moslem Ouled and Hammami, Imen and Foucher, Samuel and
	Lepage, Richard},
  month     = jul,
  year      = {2017},
  note      = {ISSN: 2153-7003},
  keywords  = {Synthetic aperture radar, Feature extraction, Rivers, Fuzzy logic,
	Radar imaging, Surface morphology, Flood mapping, texture analysis,
	mathematical morphology, fuzzy logic, RADARSAT-2 images},
  pages     = {1900--1903}
}

@article{ojala_multiresolution_2002,
  title    = {Multiresolution gray-scale and rotation invariant texture
	classification with local binary patterns},
  volume   = {24},
  issn     = {1939-3539},
  doi      = {10.1109/TPAMI.2002.1017623},
  abstract = {Presents a theoretically very
	simple, yet efficient, multiresolution approach to gray-scale and rotation
	invariant texture classification based on local binary patterns and
	nonparametric discrimination of sample and prototype distributions. The method
	is based on recognizing that certain local binary patterns, termed "uniform,"
	are fundamental properties of local image texture and their occurrence
	histogram is proven to be a very powerful texture feature. We derive a
	generalized gray-scale and rotation invariant operator presentation that
	allows for detecting the "uniform" patterns for any quantization of the
	angular space and for any spatial resolution and presents a method for
	combining multiple operators for multiresolution analysis. The proposed
	approach is very robust in terms of gray-scale variations since the operator
	is, by definition, invariant against any monotonic transformation of the gray
	scale. Another advantage is computational simplicity as the operator can be
	realized with a few operations in a small neighborhood and a lookup table.
	Experimental results demonstrate that good discrimination can be achieved with
	the occurrence statistics of simple rotation invariant local binary
	patterns.},
  number   = {7},
  journal  = {IEEE Transactions on Pattern Analysis and
	Machine Intelligence},
  author   = {Ojala, T. and Pietikainen, M. and Maenpaa,
	T.},
  month    = jul,
  year     = {2002},
  keywords = {Gray-scale, Spatial resolution,
	Prototypes, Pattern recognition, Image recognition, Image texture, Histograms,
	Quantization, Multiresolution analysis, Robustness},
  pages    = {971--987}
}

@article{badrinarayanan_segnet:_2017,
  title      = {{SegNet}: {A} {Deep} {Convolutional} {Encoder}-{Decoder}
	{Architecture} for {Image} {Segmentation}},
  volume     = {39},
  issn       = {1939-3539},
  shorttitle = {{SegNet}},
  doi        = {10.1109/TPAMI.2016.2644615},
  abstract   = {We
	present a novel and practical deep fully convolutional neural network
	architecture for semantic pixel-wise segmentation termed SegNet. This core
	trainable segmentation engine consists of an encoder network, a corresponding
	decoder network followed by a pixel-wise classification layer. The
	architecture of the encoder network is topologically identical to the 13
	convolutional layers in the VGG16 network [1] . The role of the decoder
	network is to map the low resolution encoder feature maps to full input
	resolution feature maps for pixel-wise classification. The novelty of SegNet
	lies is in the manner in which the decoder upsamples its lower resolution
	input feature map(s). Specifically, the decoder uses pooling indices computed
	in the max-pooling step of the corresponding encoder to perform non-linear
	upsampling. This eliminates the need for learning to upsample. The upsampled
	maps are sparse and are then convolved with trainable filters to produce dense
	feature maps. We compare our proposed architecture with the widely adopted FCN
	[2] and also with the well known DeepLab-LargeFOV [3] , DeconvNet [4]
	architectures. This comparison reveals the memory versus accuracy trade-off
	involved in achieving good segmentation performance. SegNet was primarily
	motivated by scene understanding applications. Hence, it is designed to be
	efficient both in terms of memory and computational time during inference. It
	is also significantly smaller in the number of trainable parameters than other
	competing architectures and can be trained end-to-end using stochastic
	gradient descent. We also performed a controlled benchmark of SegNet and other
	architectures on both road scenes and SUN RGB-D indoor scene segmentation
	tasks. These quantitative assessments show that SegNet provides good
	performance with competitive inference time and most efficient inference
	memory-wise as compared to other architectures. We also provide a Caffe
	implementation of SegNet and a web demo at
	http://mi.eng.cam.ac.uk/projects/segnet/.},
  number     = {12},
  journal    = {IEEE
	Transactions on Pattern Analysis and Machine Intelligence},
  author     = {Badrinarayanan, Vijay and Kendall, Alex and Cipolla, Roberto},
  month      = dec,
  year       = {2017},
  keywords   = {Decoding, Neural networks, Training, Computer
	architecture, Image segmentation, Semantics, Convolutional codes, Deep
	convolutional neural networks, semantic pixel-wise segmentation, indoor
	scenes, road scenes, encoder, decoder, pooling, upsampling},
  pages      = {2481--2495}
}



@Comment{jabref-meta: databaseType:bibtex;}